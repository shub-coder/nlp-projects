{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STEMMING AND LEMMANTIZATIONipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw0iaRkRwACH"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov4TkF5hMjx0"
      },
      "source": [
        "##PORTER STEMMER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfut-zzp3fBu"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLrD5kch3m3n"
      },
      "source": [
        "p_stemmer = PorterStemmer()"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eDtHJVK3rnp"
      },
      "source": [
        "words = ['have', 'having','had', 'hang', 'hanging', 'run', 'ran', 'runner', 'fair', 'fairly', 'nationality', 'nationalism', 'national', 'fairness']"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_KrWLTg37I2",
        "outputId": "cf760ea7-9e04-4872-fea3-7162c512e307"
      },
      "source": [
        "for word in words:\r\n",
        "  print(word + '----->' + p_stemmer.stem(word))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "have----->have\n",
            "having----->have\n",
            "had----->had\n",
            "hang----->hang\n",
            "hanging----->hang\n",
            "run----->run\n",
            "ran----->ran\n",
            "runner----->runner\n",
            "fair----->fair\n",
            "fairly----->fairli\n",
            "nationality----->nation\n",
            "nationalism----->nation\n",
            "national----->nation\n",
            "fairness----->fair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SDaB6KiMojd"
      },
      "source": [
        "##SNOWBALL STEMMER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1syzEv0E4OaJ"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdkIRjlJ44LF"
      },
      "source": [
        "s_stemmer = SnowballStemmer(language = 'english')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQsJoa_O48IS",
        "outputId": "7f57ae91-be22-43dd-e85d-597d811ce1e4"
      },
      "source": [
        "for word in words:\r\n",
        "  print(word + '----->' + s_stemmer.stem(word))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "have----->have\n",
            "having----->have\n",
            "had----->had\n",
            "hang----->hang\n",
            "hanging----->hang\n",
            "run----->run\n",
            "ran----->ran\n",
            "runner----->runner\n",
            "fair----->fair\n",
            "fairly----->fair\n",
            "nationality----->nation\n",
            "nationalism----->nation\n",
            "national----->nation\n",
            "fairness----->fair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1InS68B-Mzs0"
      },
      "source": [
        "##LEMMANTIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anzJ9Hg8C9nC"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsltZRdBEiml"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RiwHy02Enq7"
      },
      "source": [
        "doc = nlp(u'Peter Piper picked a peck of pickled peppers')"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iFV2N8rE7OM",
        "outputId": "7de4b22f-9bde-476f-dfee-d0d3c9bfb376"
      },
      "source": [
        "for token in doc:\r\n",
        "  print(token, '\\t', token.dep_, '\\t', token.pos_, '\\t', token.lemma, '\\t', token.lemma_)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peter \t compound \t PROPN \t 12811822816318728671 \t Peter\n",
            "Piper \t nsubj \t PROPN \t 16272889730469212282 \t Piper\n",
            "picked \t ROOT \t VERB \t 14020768407998353649 \t pick\n",
            "a \t det \t DET \t 11901859001352538922 \t a\n",
            "peck \t dobj \t NOUN \t 17237996080690907035 \t peck\n",
            "of \t prep \t ADP \t 886050111519832510 \t of\n",
            "pickled \t amod \t VERB \t 15206147607577397413 \t pickle\n",
            "peppers \t pobj \t NOUN \t 7406717370878359568 \t pepper\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptPCbdQUF_hN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}