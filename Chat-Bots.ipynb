{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHATBOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': 1,\n",
       " '?': 2,\n",
       " 'took': 3,\n",
       " 'the': 4,\n",
       " '.': 5,\n",
       " 'left': 6,\n",
       " 'grabbed': 7,\n",
       " 'apple': 8,\n",
       " 'to': 9,\n",
       " 'is': 10,\n",
       " 'office': 11,\n",
       " 'dropped': 12,\n",
       " 'mary': 13,\n",
       " 'discarded': 14,\n",
       " 'down': 15,\n",
       " 'there': 16,\n",
       " 'kitchen': 17,\n",
       " 'no': 18,\n",
       " 'went': 19,\n",
       " 'up': 20,\n",
       " 'football': 21,\n",
       " 'milk': 22,\n",
       " 'moved': 23,\n",
       " 'travelled': 24,\n",
       " 'sandra': 25,\n",
       " 'put': 26,\n",
       " 'bedroom': 27,\n",
       " 'journeyed': 28,\n",
       " 'picked': 29,\n",
       " 'bathroom': 30,\n",
       " 'daniel': 31,\n",
       " 'back': 32,\n",
       " 'got': 33,\n",
       " 'john': 34,\n",
       " 'in': 35,\n",
       " 'hallway': 36,\n",
       " 'garden': 37}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  4, 27,  5],\n",
       "       [ 0,  0,  0, ...,  4, 37,  5],\n",
       "       [ 0,  0,  0, ...,  4, 37,  5],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  4,  8,  5],\n",
       "       [ 0,  0,  0, ...,  4, 37,  5],\n",
       "       [ 0,  0,  0, ...,  8, 16,  5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 34, 35,  4, 17,  2],\n",
       "       [10, 34, 35,  4, 17,  2],\n",
       "       [10, 34, 35,  4, 37,  2],\n",
       "       ...,\n",
       "       [10, 13, 35,  4, 27,  2],\n",
       "       [10, 25, 35,  4, 37,  2],\n",
       "       [10, 13, 35,  4, 37,  2]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shubhendu\\.conda\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shubhendu\\.conda\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\shubhendu\\.conda\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.8922 - accuracy: 0.5016 - val_loss: 0.6956 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 6s 621us/step - loss: 0.7067 - accuracy: 0.4939 - val_loss: 0.6948 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 6s 592us/step - loss: 0.6971 - accuracy: 0.4966 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 6s 590us/step - loss: 0.6946 - accuracy: 0.5021 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 6s 593us/step - loss: 0.6949 - accuracy: 0.4984 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 6s 586us/step - loss: 0.6944 - accuracy: 0.5004 - val_loss: 0.6963 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 6s 594us/step - loss: 0.6948 - accuracy: 0.4944 - val_loss: 0.6955 - val_accuracy: 0.4970\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 6s 590us/step - loss: 0.6937 - accuracy: 0.5073 - val_loss: 0.6944 - val_accuracy: 0.4960\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 6s 594us/step - loss: 0.6937 - accuracy: 0.5055 - val_loss: 0.6970 - val_accuracy: 0.4960\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 6s 588us/step - loss: 0.6943 - accuracy: 0.5063 - val_loss: 0.6941 - val_accuracy: 0.4740\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 6s 590us/step - loss: 0.6935 - accuracy: 0.5109 - val_loss: 0.6944 - val_accuracy: 0.4850\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 6s 593us/step - loss: 0.6930 - accuracy: 0.5138 - val_loss: 0.6950 - val_accuracy: 0.4870\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.6923 - accuracy: 0.5230 - val_loss: 0.6987 - val_accuracy: 0.4920\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 6s 585us/step - loss: 0.6903 - accuracy: 0.5275 - val_loss: 0.6949 - val_accuracy: 0.5110\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 6s 589us/step - loss: 0.6767 - accuracy: 0.5745 - val_loss: 0.6732 - val_accuracy: 0.5740\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 6s 586us/step - loss: 0.6572 - accuracy: 0.6069 - val_loss: 0.6539 - val_accuracy: 0.6240\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 6s 579us/step - loss: 0.6388 - accuracy: 0.6425 - val_loss: 0.6346 - val_accuracy: 0.6560\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 6s 582us/step - loss: 0.6273 - accuracy: 0.6515 - val_loss: 0.6213 - val_accuracy: 0.6640\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 6s 588us/step - loss: 0.6071 - accuracy: 0.6766 - val_loss: 0.5943 - val_accuracy: 0.6870\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 6s 579us/step - loss: 0.5838 - accuracy: 0.6938 - val_loss: 0.5618 - val_accuracy: 0.7110\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 6s 583us/step - loss: 0.5545 - accuracy: 0.7170 - val_loss: 0.5321 - val_accuracy: 0.7260\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 6s 585us/step - loss: 0.5377 - accuracy: 0.7251 - val_loss: 0.5218 - val_accuracy: 0.7250\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 6s 578us/step - loss: 0.5229 - accuracy: 0.7358 - val_loss: 0.4965 - val_accuracy: 0.7550\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 6s 574us/step - loss: 0.5055 - accuracy: 0.7520 - val_loss: 0.5014 - val_accuracy: 0.7520\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 6s 578us/step - loss: 0.4936 - accuracy: 0.7575 - val_loss: 0.4878 - val_accuracy: 0.7540\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 6s 585us/step - loss: 0.4765 - accuracy: 0.7721 - val_loss: 0.4903 - val_accuracy: 0.7580\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 6s 579us/step - loss: 0.4708 - accuracy: 0.7731 - val_loss: 0.4643 - val_accuracy: 0.7830\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 6s 574us/step - loss: 0.4614 - accuracy: 0.7801 - val_loss: 0.4627 - val_accuracy: 0.7680\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.4569 - accuracy: 0.7858 - val_loss: 0.4503 - val_accuracy: 0.7710\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 0.4513 - accuracy: 0.7872 - val_loss: 0.4539 - val_accuracy: 0.7830\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 6s 571us/step - loss: 0.4430 - accuracy: 0.7954 - val_loss: 0.4559 - val_accuracy: 0.7830\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.4320 - accuracy: 0.7996 - val_loss: 0.4403 - val_accuracy: 0.7690\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.4342 - accuracy: 0.7981 - val_loss: 0.4411 - val_accuracy: 0.7680\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 6s 574us/step - loss: 0.4297 - accuracy: 0.8020 - val_loss: 0.4274 - val_accuracy: 0.7830\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.4262 - accuracy: 0.8069 - val_loss: 0.4541 - val_accuracy: 0.7850\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 6s 564us/step - loss: 0.4227 - accuracy: 0.8045 - val_loss: 0.4269 - val_accuracy: 0.7850\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 6s 561us/step - loss: 0.4161 - accuracy: 0.8070 - val_loss: 0.4369 - val_accuracy: 0.7890\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.4156 - accuracy: 0.8083 - val_loss: 0.4146 - val_accuracy: 0.7970\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.3989 - accuracy: 0.8211 - val_loss: 0.4197 - val_accuracy: 0.7920\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 6s 571us/step - loss: 0.3975 - accuracy: 0.8223 - val_loss: 0.4048 - val_accuracy: 0.7950\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.3839 - accuracy: 0.8296 - val_loss: 0.4065 - val_accuracy: 0.8120\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 6s 569us/step - loss: 0.3792 - accuracy: 0.8322 - val_loss: 0.3953 - val_accuracy: 0.8150\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.3732 - accuracy: 0.8366 - val_loss: 0.3893 - val_accuracy: 0.8200\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 6s 558us/step - loss: 0.3646 - accuracy: 0.8402 - val_loss: 0.3861 - val_accuracy: 0.8190\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 0.3585 - accuracy: 0.8415 - val_loss: 0.3765 - val_accuracy: 0.8170\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 6s 557us/step - loss: 0.3573 - accuracy: 0.8426 - val_loss: 0.3989 - val_accuracy: 0.8160\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 0.3525 - accuracy: 0.8463 - val_loss: 0.3737 - val_accuracy: 0.8200\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 0.3460 - accuracy: 0.8487 - val_loss: 0.3815 - val_accuracy: 0.8110\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 6s 560us/step - loss: 0.3459 - accuracy: 0.8500 - val_loss: 0.3756 - val_accuracy: 0.8310\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 6s 551us/step - loss: 0.3402 - accuracy: 0.8528 - val_loss: 0.3784 - val_accuracy: 0.8250\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 6s 588us/step - loss: 0.3375 - accuracy: 0.8558 - val_loss: 0.3783 - val_accuracy: 0.8240\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 6s 594us/step - loss: 0.3367 - accuracy: 0.8517 - val_loss: 0.3732 - val_accuracy: 0.8320\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 6s 589us/step - loss: 0.3370 - accuracy: 0.8546 - val_loss: 0.3593 - val_accuracy: 0.8400\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 6s 589us/step - loss: 0.3267 - accuracy: 0.8569 - val_loss: 0.3714 - val_accuracy: 0.8270\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 6s 586us/step - loss: 0.3263 - accuracy: 0.8602 - val_loss: 0.3613 - val_accuracy: 0.8300\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 6s 650us/step - loss: 0.3280 - accuracy: 0.8551 - val_loss: 0.3744 - val_accuracy: 0.8170\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 6s 630us/step - loss: 0.3263 - accuracy: 0.8611 - val_loss: 0.3749 - val_accuracy: 0.8270\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 6s 627us/step - loss: 0.3197 - accuracy: 0.8592 - val_loss: 0.3736 - val_accuracy: 0.8270\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 6s 638us/step - loss: 0.3206 - accuracy: 0.8586 - val_loss: 0.3648 - val_accuracy: 0.8220\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 6s 641us/step - loss: 0.3214 - accuracy: 0.8633 - val_loss: 0.3610 - val_accuracy: 0.8280\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 6s 635us/step - loss: 0.3209 - accuracy: 0.8644 - val_loss: 0.3540 - val_accuracy: 0.8340\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 0.3245 - accuracy: 0.8602 - val_loss: 0.3610 - val_accuracy: 0.8360\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 6s 587us/step - loss: 0.3156 - accuracy: 0.8659 - val_loss: 0.3600 - val_accuracy: 0.8320\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 0.3183 - accuracy: 0.8648 - val_loss: 0.3757 - val_accuracy: 0.8290\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 6s 575us/step - loss: 0.3167 - accuracy: 0.8618 - val_loss: 0.3537 - val_accuracy: 0.8300\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 6s 581us/step - loss: 0.3105 - accuracy: 0.8607 - val_loss: 0.3640 - val_accuracy: 0.8330\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.3176 - accuracy: 0.8613 - val_loss: 0.3668 - val_accuracy: 0.8240\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.3112 - accuracy: 0.8651 - val_loss: 0.3559 - val_accuracy: 0.8350\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 6s 575us/step - loss: 0.3036 - accuracy: 0.8694 - val_loss: 0.3603 - val_accuracy: 0.8340\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 6s 573us/step - loss: 0.3082 - accuracy: 0.8693 - val_loss: 0.3593 - val_accuracy: 0.8410\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.3080 - accuracy: 0.8649 - val_loss: 0.3744 - val_accuracy: 0.8280\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 6s 571us/step - loss: 0.3078 - accuracy: 0.8661 - val_loss: 0.3643 - val_accuracy: 0.8380\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 6s 569us/step - loss: 0.3076 - accuracy: 0.8644 - val_loss: 0.3748 - val_accuracy: 0.8220\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 6s 572us/step - loss: 0.3025 - accuracy: 0.8690 - val_loss: 0.3757 - val_accuracy: 0.8310\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.3053 - accuracy: 0.8682 - val_loss: 0.3542 - val_accuracy: 0.8330\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 6s 572us/step - loss: 0.2985 - accuracy: 0.8702 - val_loss: 0.3677 - val_accuracy: 0.8320\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.2993 - accuracy: 0.8715 - val_loss: 0.3773 - val_accuracy: 0.8300\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.3042 - accuracy: 0.8697 - val_loss: 0.3729 - val_accuracy: 0.8280\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.3062 - accuracy: 0.8650 - val_loss: 0.3737 - val_accuracy: 0.8330\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 6s 573us/step - loss: 0.2957 - accuracy: 0.8720 - val_loss: 0.3614 - val_accuracy: 0.8330\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.3005 - accuracy: 0.8709 - val_loss: 0.3685 - val_accuracy: 0.8280\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 6s 563us/step - loss: 0.2971 - accuracy: 0.8729 - val_loss: 0.3623 - val_accuracy: 0.8330\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 6s 573us/step - loss: 0.2923 - accuracy: 0.8696 - val_loss: 0.3738 - val_accuracy: 0.8340\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 6s 561us/step - loss: 0.2959 - accuracy: 0.8730 - val_loss: 0.3805 - val_accuracy: 0.8350\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.2940 - accuracy: 0.8738 - val_loss: 0.3606 - val_accuracy: 0.8320\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.2941 - accuracy: 0.8728 - val_loss: 0.3669 - val_accuracy: 0.8350\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.2885 - accuracy: 0.8762 - val_loss: 0.3556 - val_accuracy: 0.8370\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 6s 561us/step - loss: 0.2969 - accuracy: 0.8702 - val_loss: 0.3611 - val_accuracy: 0.8310\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 6s 562us/step - loss: 0.2929 - accuracy: 0.8734 - val_loss: 0.3728 - val_accuracy: 0.8260\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.2935 - accuracy: 0.8735 - val_loss: 0.3823 - val_accuracy: 0.8360\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 0.2862 - accuracy: 0.8762 - val_loss: 0.3924 - val_accuracy: 0.8310\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 6s 558us/step - loss: 0.2876 - accuracy: 0.8761 - val_loss: 0.3800 - val_accuracy: 0.8320\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.2885 - accuracy: 0.8760 - val_loss: 0.3717 - val_accuracy: 0.8270\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 0.2826 - accuracy: 0.8797 - val_loss: 0.3955 - val_accuracy: 0.8260\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 6s 558us/step - loss: 0.2819 - accuracy: 0.8796 - val_loss: 0.3845 - val_accuracy: 0.8250\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 6s 596us/step - loss: 0.2820 - accuracy: 0.8797 - val_loss: 0.3924 - val_accuracy: 0.8280\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.87 - 5s 538us/step - loss: 0.2849 - accuracy: 0.8797 - val_loss: 0.3804 - val_accuracy: 0.8270\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 6s 579us/step - loss: 0.2860 - accuracy: 0.8810 - val_loss: 0.3941 - val_accuracy: 0.8270\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 6s 636us/step - loss: 0.2780 - accuracy: 0.8786 - val_loss: 0.3776 - val_accuracy: 0.8290\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.2727 - accuracy: 0.8829 - val_loss: 0.3829 - val_accuracy: 0.8340\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 6s 643us/step - loss: 0.2742 - accuracy: 0.8852 - val_loss: 0.3813 - val_accuracy: 0.8350\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 7s 670us/step - loss: 0.2820 - accuracy: 0.8821 - val_loss: 0.3870 - val_accuracy: 0.8260\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.2812 - accuracy: 0.8809 - val_loss: 0.3729 - val_accuracy: 0.8280\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 6s 648us/step - loss: 0.2759 - accuracy: 0.8816 - val_loss: 0.3836 - val_accuracy: 0.8260\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 7s 665us/step - loss: 0.2696 - accuracy: 0.8867 - val_loss: 0.4010 - val_accuracy: 0.8240\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.2735 - accuracy: 0.8859 - val_loss: 0.3824 - val_accuracy: 0.8280\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 6s 621us/step - loss: 0.2695 - accuracy: 0.8865 - val_loss: 0.4000 - val_accuracy: 0.8220\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 6s 629us/step - loss: 0.2635 - accuracy: 0.8887 - val_loss: 0.3913 - val_accuracy: 0.8290\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 6s 620us/step - loss: 0.2649 - accuracy: 0.8879 - val_loss: 0.3914 - val_accuracy: 0.8270\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 0.2701 - accuracy: 0.8860 - val_loss: 0.3938 - val_accuracy: 0.8250\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 6s 613us/step - loss: 0.2671 - accuracy: 0.8875 - val_loss: 0.4173 - val_accuracy: 0.8310\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 6s 592us/step - loss: 0.2675 - accuracy: 0.8857 - val_loss: 0.4202 - val_accuracy: 0.8200\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 6s 649us/step - loss: 0.2684 - accuracy: 0.8863 - val_loss: 0.3950 - val_accuracy: 0.8270\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.2617 - accuracy: 0.8889 - val_loss: 0.4240 - val_accuracy: 0.8200\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 6s 573us/step - loss: 0.2638 - accuracy: 0.8914 - val_loss: 0.4184 - val_accuracy: 0.8230\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 6s 585us/step - loss: 0.2618 - accuracy: 0.8900 - val_loss: 0.4324 - val_accuracy: 0.8210\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 6s 599us/step - loss: 0.2622 - accuracy: 0.8898 - val_loss: 0.4270 - val_accuracy: 0.8180\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 6s 569us/step - loss: 0.2685 - accuracy: 0.8869 - val_loss: 0.4063 - val_accuracy: 0.8200\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 6s 552us/step - loss: 0.2582 - accuracy: 0.8883 - val_loss: 0.4091 - val_accuracy: 0.8140\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.2602 - accuracy: 0.8890 - val_loss: 0.4020 - val_accuracy: 0.8210\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999815\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.96905434\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
